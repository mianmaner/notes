### LLM数据处理

#### 质量过滤

方法可以大致分为两类

- 基于分类器的方法：目标是训练文本质量判断模型，并利用该模型识别并过滤低质量数据（GPT-3、PALM、GLam）
- 基于启发式的方法：则通过一组精心设计的规则来消除低质量文本(BLOOM、Gopher)

#### 冗余去除

文本冗余发现（Text Duplicate Detection）也称为文本重复检测，是自然语言处理和信息 检索中的基础任务之一

> 包含重复单词或短语的句子很可能造成语言建模中引入重复的 模式。这对语言模型来说会产生非常严重的影响，使得模型在预测时容易陷入重复循环

公共子串匹配、表面特征相似度检测（例如 n-gram 重叠比例）等等

在实际产生预训练数据时，需要从数据集、文档以及句子三个级别去除重复，这对于改善语言模型的训练具有重要的作用

#### 隐私消除

删除隐私数据最直接的方法是采用基于规则的算法，例如基于命名实体识别的方法，利用命名实体识别算法检测姓名、地址和电话号码等个 人信息内容并进行删除或者替换

#### 词元切分

##### OOV

在使用中，如果遇到不在词表中的未登 录词，模型无法为其生成对应的表示，只能给予这些未登录词（OOV）一个默认 的通用表示。

在深度学习模型中，词表示模型会预先在词表中加入一个默认的 [UNK] 标识，表示未知词，并在训练的过程中将 [UNK] 的向量作为词表示矩阵的一部分一起训练，通过 引入某些相应机制来更新 [UNK] 向量的参数。在使用时，对于全部的未登录词，都使用 [UNK] 的 向量作为这些词的表示向量

##### 词元

研究人员们提出了子词词元化方法，试图缓解上文介绍的未登录词问题。

词元分析（Tokenization）目标是将原始文本分割成由词元（Token）序列的 过程。词元切分也是数据预处理中至关重要的一步

**字节对编码（BPE）**模型是一种常见的子词词元模型。BPE 算法包括两个部分：

![image-20240509115839193](https://gitee.com/mianmann/drawing-bed-warehouse/raw/master/img/image-20240509115839193.png)

**WordPiece** 也是一种常见的词元分析算法，最初应用于语音搜索系统。此后，该算法做为 BERT 的分词器。WordPiece 与 BPE 有非常相似的思想，都是通过迭代地合并连续的词元，但在 合并的选择标准上略有不同。为了进行合并，WordPiece 需要首先训练一个语言模型，并用该语言 模型对所有可能的词元对进行评分。在每次合并时，选择使得训练数据似然概率增加最多的词元对。
## 人工智能导论

==搜索的方法，搜索的剪枝要考==

==人工智能的定义==

==搜索（这一节必考）==

==博弈树的alpha-beta剪枝必考==

==归结原理会考小题目==

==对GPT的思考==

==八数码问题（https://blog.csdn.net/weixin_42214698/article/details/122265416）==

==归结原理例题（https://www.onandon.top/post/ren-gong-zhi-neng-luo-ji-tui-li-ti-1/）==

==纳什均衡的寻找（https://www.zhihu.com/question/24279461）==

#### 第一、二讲

##### ==1.人工智能的定义（必考）==

宽泛的说，手的延长是机器，脑的延长就是人工智能。人工智能的定义有很多种：

- 从机器的角度，人工智能就是在各类环境中能自主或交互的执行各种拟人任务的机器
- 从学科的角度，人工智能是计算机科学中涉及研究、设计和应用智能机器的一个分支
- 从能力的角度，人工智能是智能机器所执行的通常与人类智能有关的智能行为，如判断、推理、思考、感知、学习等
- 涉及拟人思维：①人工智能是一种使计算机能够思维，使机器具有智力的激动人心的新尝试 ②人工智能是那些与人的思维、决策、问题求解和学习等有关活动的自动化
- 设计理性思维：①人工智能是用计算模型研究智力行为 ②人工智能是研究那些使理解、推理和行动成为可能的计算
- 涉及拟人行为：①人工智能是一种能够执行需要的人的智能的创造性机器的技术 ②人工智能研究如何使计算机做事让人过的更好
- 设计拟人理性行为：①人工智能是一门通过计算过程力图理解和模仿智能行为的学科 ②人工智能是计算机科学中智能行为的自动化有关的一个分支
- 其他

> 自动控制类、科学计算类、固定了算法的，基本上都不算AI

##### 2.人工智能与软件工程

计算机的环境是一层层构造出来的，如何构造出用于人工智能的运行环境，就是软件工程的事情

##### 3.强人工智能和弱人工智能

- 弱人工智能：某个特定方面上的人工智能
- 强人工智能：综合的多方面的人工智能

##### 4.人工智能的三大流派

- 符号主义：把现实的物，映射到代表它的符号，在符号上完成所有的推理、计算等等。
  (是最经典、接受程度最高的人工智能)
- 连接主义：人脑就是神经元和之间的一些连接，模拟人脑的做法，提出了神经网络模型
- 行为主义：智能来自更低级的感知和行动，表现的好就行（无人机、波士顿动力狗）

##### 5.人工智能三次浪潮（掌握）

![image-20231221163038574](https://gitee.com/mianmann/drawing-bed-warehouse/raw/master/img/image-20231221163038574.png)

- 早期人工智能：科技贵族的专属品
- 中期人工智能：以专家系统为代表，介于自动化和计算机之间
- 新人工智能：介于计算机和软件之间

##### 6.人工智能的应用领域

- 机器定理证明
- 博弈
- 模式识别
- 自然语言处理
- 数据挖掘和知识发现
- 专家系统

##### 7.图灵机

- 定义：是一个数学概念，一个七元组

  | 纸带 | 符号 | 读写头 | 规则 | 状态 | 起始 | 结束 |
  | ---- | ---- | ------ | ---- | ---- | ---- | ---- |
  | 存储 | 符号 | 读写   | 程序 | 数据 | 开始 | 结束 |

- 哥德尔不完备定理：任何包含自然数定义的形式系统都是不完全的，也就是存在不能证明为真，也不能证明为假的命题

- 图灵机的可计算性：不可计算的占了大部分

#### 第三、四讲

##### 1.大数据的影响

大数据与人工智能密切相关，并且大数据成为人工智能的营养、方法的来源。总的来说，大数据、人工智能都很重要，会改变我们的社会。

> 大数据（big data），指无法在一定时间范围内用常规 软件工具进行捕捉、管理和处理的数据集合，是需要 新处理模式才能具有更强的决策力、洞察发现力和流 程优化能力的海量、高增长率和多样化的信息资产。

##### 2.人工智能的影响

- 人工智能使得社会形态发生变化：物质极大丰富、失业人口和无需工作的人口剧增......
- 国家发展的一次重要机遇

##### 3.大数据特点

- Volume（大量）
- Velocity（高速）
- Variety（多样）
- Value（低价值密度）
- Veracity（真实性）

#### 第五讲

##### 1.专家系统（产生式系统）的组成

- 组成三要素：
  ①一个综合数据库——存放信息
  ②一组产生式规则——知识
  ③一个控制系统——规则的解释或执行程序

- 基本过程：

  ```c
  DATA<-初始数据库
  until DATA满足结束条件, do
  {
  	在规则集中选择一条可应用于DATA的规则R
  	DATA<-R应用到DATA得到的结果
  }
  ```
  
- 例题：（见 PPT 第五讲，要掌握！）

  ①字符转换

  ②传教士与野人（M-C问题）

  ③猴子摘香蕉

##### 2.产生式系统的特点

- 数据驱动
- 知识的无序性
- 控制系统与问题无关
- 数据、知识和控制相互独立

##### 2.产生式系统的类型

- 正向、逆向、双向产生式系统

  ①正向推理：从已知事实出发，通过规则库求得结束（自底向上驱动方式）
  ②反向推理：从目标出发，反向使用规则，求得已知事实（自顶向下驱动方式）
  ③双向推理：同时正向和反向，知道某个中间环节两个方向的结果相符便成功结束

- 可交换的产生式系统

- 可分解的产生式系统

##### 3.产生式系统的搜索方式

- 启发式搜索
- 盲目搜索

##### 4.产生式系统的搜索策略

(1)回溯策略：皇后问题

```c
result = []
def backtrack(路径, 选择列表):
    if 满足结束条件:
        result.add(路径)
        return
 
    for 选择 in 选择列表:
        做选择
        backtrack(路径, 选择列表)
        撤销选择
    return
```

(2)图搜索策略

- 回溯搜索：只保留从初始状态到当前状态的一条路径，不是图搜索

- 图搜索：保留所有已经搜索过的路径

  ①深度优先搜索：一般不能保证找到最优解，当深度限制不合理时，可能找不到解
  ②宽度优先搜索：当问题有解时，一定能找到解，当问题为单位耗散值，且问题有解时，一定能找到最优解

  ③渐进式深度优先搜素方法：解决宽度优先方法的空间问题和回溯方法不能找到最优解的问题
  (首先给回溯法一个比较小的深度限制，然后逐 渐增加深度限制，直到找到解或找遍所以分支为止)

  ④启发式图搜索：利用知识来引导搜索，从而减小搜索范围
  (启发信息强会降低搜索工作量，但可能导致找不到最优解；启发信息弱导致工作量加大，极限情况变为盲目搜索，但可能可以找到最优解)

- 启发式搜索算法A：$f(n)=g(n)+h(n)$

  ①$g(n)$：从初始状态到状态n的代价
  ②$h(n)$：从状态n到目标状态的代价（启发函数）

  ![image-20231228172818281](C:\Users\12774\AppData\Roaming\Typora\typora-user-images\image-20231228172818281.png)
  ![image-20231228172829820](https://gitee.com/mianmann/drawing-bed-warehouse/raw/master/img/image-20231228172829820.png)

- 最佳图搜索算法A\*

(3)最佳图搜索算法A\*（其实和上面并列，单拎出来是因为内容实在太多)

> OPEN表：一个记录下所有被考虑来寻找最短路径的方块（意思就是OPEN表中所有的点都满足$h(n)\le h^*(n)$）
> CLOSED表：一个记录下不会再被考虑的方块

- 最佳图搜索算法A\*（A\*算法）：在A算法中，如果满足条件$h(n)\le h^*(n)$，则A算法称为A\*算法
  ($h^*(n)$是最接近目标的真实代价，$h(n)$是实际$A^*$算法拟合的函数)

- $A^*$算法的假设：设$n_i,n_j$是任意两个节点，有：$C(N_i,N_j)>\epsilon$(其中$\epsilon$为大于0的常数)

- 几个等式：$f^*(s)=f^*(t)=h^*(s)=g^*(t)=f^*(n)$
  (s是初始节点，t是目标节点，n是s到t的最佳路径上的节点)

- 定理1：对有限图，如果从初始节点s到目标节点t有路径存在，则算法A一定成功结束

- 定理2：对无限图，若从初始节点s到目标节点t有路径存在， 则A*一定成功结束

  ①引理2.1：对无限图，若有从初始节点s到目标节点t的路径， 则A\*不能成功结束时，在OPEN表中即使最小的一个f值也将增到任意大，或有$f(n)>f^*(s)$

  ②引理2.2：A\*结束前，OPEN表中必存在$f(n)\le f^*(s)$

  (由引理2.1和2.2可以得到A*必会结束)

  ③推论2.1：OPEN表上任一具有$f(n)<f^*(s)$的节点n，最终都将被A\*选作扩展的节点

- 定理3（可采纳性定理）：若存在从初始节点s到目标节点t有路径，则A\*必能找到最佳解结束

  ①推论3.1：A\*选作扩展的任一节点n，有$f(n)\le f^*(s)$

- 定理4：如果$h2(n) > h1(n) $(目标节点除外)，则A1扩展的节点数≥A2扩展的节点数
- 定理5：若h(n)是单调的，则A*扩展了节点n之后，就已经找 到了到达节点n的最佳路径
- 定理6：若h(n)是单调的，则由A*所扩展的节点序列其f值是 非递减的。即$f(n_i) ≤ f(n_j)$

(4)博弈树搜索

- 博弈问题

- α-β剪枝：

  ①极大节点的下界为α，极小节点的上界为β
  ②剪枝的条件：后辈节点的β值≤祖先节点的α值时，α剪枝；后辈节点的α值≥祖先节点的β值时，β剪枝

#### 第六讲 归结原理

(1)谓词演算及应用

- 是一种形式语言，具有严密的理论体系
- 是一种常用的知识表示方法

(2)归结原理：归结原理是一种定理证明方法，==1965年由Robinson提出==，从理论上解决了定理证明问题

(3)子句集

- ①无量词约束
  ②元素只是文字的析取
  ③否定符只作用于单个文字
  ④元素间默认为合取

- 化子句集的方法

  ①消蕴含符
  ![image-20231224200323307](https://gitee.com/mianmann/drawing-bed-warehouse/raw/master/img/image-20231224200323307.png)

  ②移动否定符
  ![image-20231224202843863](https://gitee.com/mianmann/drawing-bed-warehouse/raw/master/img/image-20231224202843863.png)
  
  ③变量标准化
  ![image-20231224203341337](https://gitee.com/mianmann/drawing-bed-warehouse/raw/master/img/image-20231224203341337.png)
  
  ④量词左移
  ![image-20231224203459181](https://gitee.com/mianmann/drawing-bed-warehouse/raw/master/img/image-20231224203459181.png)
  
  ⑤消存在量词
  ![image-20231224203736712](https://gitee.com/mianmann/drawing-bed-warehouse/raw/master/img/image-20231224203736712.png)
  
  ⑥化为合取范式
  ![image-20231224204116711](https://gitee.com/mianmann/drawing-bed-warehouse/raw/master/img/image-20231224204116711.png)
  
  ⑦隐去全程量词
  ![image-20231224204250335](https://gitee.com/mianmann/drawing-bed-warehouse/raw/master/img/image-20231224204250335.png)
  
  ⑧表示为子句集
  ![image-20231224204309944](https://gitee.com/mianmann/drawing-bed-warehouse/raw/master/img/image-20231224204309944.png)
  
  ⑨变量标准化
  ![image-20231224204330192](https://gitee.com/mianmann/drawing-bed-warehouse/raw/master/img/image-20231224204330192.png)

(4)归结原理

- 定理：若S是合式公式F的子句集，则F永假的充要条件是S不可满足。（若$nil \in S$，则$S$不可满足）

- 使用归结原理证明定理的思路：将目标的否定连同已知条件一起，化为子句集，并给出一种变换的方法，使得$S->S_1->\cdots ->S_n$同时保证当$S_n$不可满足时，有$S$不可满足

- 例子：

  ![image-20231228092830246](https://gitee.com/mianmann/drawing-bed-warehouse/raw/master/img/image-20231228092830246.png)
  ![image-20231228092840478](C:\Users\12774\AppData\Roaming\Typora\typora-user-images\image-20231228092840478.png)

- 谓词逻辑的归结原理

  ①置换：对公式E实施置换s后得到的公式称为E的例，记作$E_s$
  ![image-20231228100349691](https://gitee.com/mianmann/drawing-bed-warehouse/raw/master/img/image-20231228100349691.png)

  ②合一：如果存在一个S置换，是的$\{E_i\}$中$E_{1s}=E_{2s}=\cdots=E_{ns}$，则称$\{E_i\}$是可合一的，S为$\{E_i\}$的合一者

  > 最一般合一者：置换最少，限制最少，产生的例最具一般性

#### 博弈论

##### 1.博弈基础

(1)博弈定义：研究智慧的理性决策者之间冲突和合作的数学模型

(2)博弈要素

- 玩家：参与博弈的决策主体

- 策略：参与者可以采取的行动方案

  ①混合策略：参与者可以通过一定概率分布来选择某确定的策略
  ②纯策略：参与者每次行动都选择某个确定的策略
  ③局势：所有参与者各自采取行动后形成的状态

- 收益：各个参与者在不同局势下得到的利益

- 规则：对参与者的先后顺序、参与者获得信息多少等内容的规定

(3)博弈六特征

- 2或多玩家
- 轮流 vs. 同时
- 完整信息 vs. 不完整信息（完全信息博弈：指每一个参与者都拥有所有其他参与者的特征、策略集及得益函数等方面的准确信息的博弈）
- 确定的 vs. 随机的
- 合作 vs. 竞争
- 零和 vs. 非零和（零和：一方的收益必然意味着另一方的损失，博弈各方的收益和损失相加的总和永远为0）

> 例子：石头剪刀布
> 2 & 同时 & 不完整 & 随机 & 竞争 & 零和

(4)占优策略

- 概念：对于玩家i，无论其他玩家做什么，如果策略x比策略y更好，策略x将主导策略y
- 不满足帕雷托效率：在没有使任何人情况变坏的前提下，至少使一个人变得更好

(5)纳什均衡

- 概念：任何参与者单独改变策略都不会获得好处，则该情形下的策略组合就是一个纳什均衡
- Nash定理：有限博弈（参与者有限，每位参与者的策略集有限，收益函数为实值函数）必存在混合策略意义下的纳什均衡

> 例子：囚徒困境
>
> |                     | **Deny** | **Confess** |
> | ------------------- | -------- | ----------- |
> | **Deny**            | (-1,-1)  | (-10,0)     |
> | **Confess（指控）** | (0,-10)  | (-8,-8)     |

##### 2.对抗搜索（博弈搜索）

(1)搜索和博弈

- 搜索：非对抗性的
  ①解决方案：（启发式）发现目标的方法
- 博弈：对抗性的
  ①解决方案：策略

(2)对抗搜索的六部分

①初始状态$S$：游戏所处的初始状态
②玩家$PLAYER(s)$：在当前状态S下，该由哪个玩家采取行动
③行动$ACTION(s)$：在当前状态S下所采取的可能移动
④状态转移模型$RESULT(s,a)$：在当前状态S下采取行动a后得到的结果
⑤终局状态检测$TERMINAL-TEST(s)$：检测游戏在状态S是否结束
⑥终局得分$UTILITY(s,p)$：在终局状态S时，玩家的得分

(3)最小最大搜索（MinMax Search）

- 最小最大搜索是在对抗搜索中最为基本的一种让玩家来计算最优策略的方法

- 例子：https://blog.csdn.net/weixin_42165981/article/details/103263211
  ![img](https://img-blog.csdnimg.cn/27e3ffa4529e486494b8ef9d144bca88.png)

- $\alpha-\beta$剪枝：一种对最小最大搜索进行改进的算法，即在搜索过程中可剪除无需搜索的分支节点，且不影响搜索结果

  ①极大节点的下界为$\alpha$，极小节点的上界为$\beta$

  ②剪枝的条件$\alpha \ge \beta$:
  $max$节点的$\alpha$值大于后辈$min$节点的$\beta$值时，$\alpha$剪枝
  $min$节点的$\beta$值小于后辈$max$节点的$\alpha$值时，$\beta$剪枝

  ③一般原则：若玩家是在位于$n$的父节点上或更上层中有更好的选择，则实战中就没必要抵达$n$

(4)蒙特卡洛树搜索

- 通过采样而非穷举的方法来实现搜索

- AlphaGo的算法

  ①深度神经网络：价值网络（评估）、策略网络（移动）
  ②蒙特卡洛搜索：结合蒙特卡洛模拟、价值网络与策略网络
  ③强化学习

- 蒙特卡洛方法：依靠重复随机采样来获取数值结果的计算算法

- ==四个步骤创建决策树：①选择②扩展③模拟④反向传播==

#### 机器学习

##### 1.定义

- 机器学习是一个对如下算法的研究

  ①提升表现P
  ②在某些任务T
  ③通过经验E
  ④一个根据$<P,T,E>$设计好的任务
  
  计算机程序可以在给定某种类别的任务 T 和性能度量 P 下学习经验 E ，如果其在任务 T 中的性能恰好可以用 P 度量，则随着经验 E 而提高

##### 2.机器学习算法分类

- 有监督学习（有标记信息）
  ①回归
  ②分类
  ③支持向量机
  ④决策树
  ⑤贝叶斯学习
  ⑥神经网络&深度学习
  ⑦学习理论
- 无监督学习（无标记信息）
  ①聚类
  ②维度约减
- 半监督学习（一部分数据有标记信息）
- 强化学习
  ①给定一系列具有（延迟）奖励的状态和动作，输出策略；策略是状态到动作的映射
  ②时间差异学习
  ③Q学习（Q Learning）

##### 3.机器学习算法组成

- 表示

  ①数值函数：线性回归、神经网络、支持向量机
  ②符号函数：决策树、命题逻辑规则、一阶谓词逻辑的规则
  ③基于实例的函数：最近邻、基于案例
  ④概率图模型：朴素贝叶斯、贝叶斯网络、隐马尔可夫链、概率上下文无关语法、马尔可夫网络

- 优化

  ①梯度下降：感知器、反向传播
  ②动态变成：隐马尔可夫学习、概率上下文无关语法学习
  ③分而治之：决策树归纳、规则学习
  ④进化计算：遗传算法、遗传编程、神经进化

- 评价

  ①精度 Accuracy
  ②精确度和召回率 Precision and Recall
  ③平方误差 Squared error
  ④相似性 Likelihood
  ⑤后验概率 Posterior Probability
  ⑥成本/效用 Cost/Utility
  ⑦边距 Margin
  ⑧熵 Entropy
  ⑨K-L散度 K-L divergence

##### 4.机器学习系统的设计

- 选择训练经验
- 选择学习对象，如目标函数
- 选择如何表示目标函数
- 选择学习算法从经验判断目标函数

##### 5.机器学习实践

- 了解领域，先验知识和目标

- 数据集成、选择、清洁、预处理
- 学习模型
- 解释结果
- 巩固和部署发现的知识

#### 深度学习

##### 1.深度学习的三步

①定义函数集（神经网络）：定义网络架构
②模型评估：训练数据、学习目标、总体损失
③选择最优函数：梯度下降，找到最优的一组参数

##### 2.监督神经网络

- Neuron、Weights、Bias、Activation Function、Output Layer

- Convolutional Neural Network（CNN）

  ①Convolution：Stride、Zero Padding
  ②MaxPooling
  ③Flatten
  ![image-20231229121947171](https://gitee.com/mianmann/drawing-bed-warehouse/raw/master/img/image-20231229121947171.png)

##### 3.非监督神经网络

- embedding（word2vec）

#### 生成模型

##### 1.定义

- 给定训练数据，从同一分布生成新样本
- 解决密度估计问题，这是无监督学习中的核心问题

##### 2.主要方向

- 显式密度估计：显式定义并求解$p_{model}(x)$
- 隐式密度估计：非显式的定义模型，而是学习可以从$p_{model}(x)$采样的模型

##### 3.应用

- 用于艺术品，超分辨率，着色的真实采样
- 时序数据的生成模型可用于仿真和计划（强化学习应用程序）
- 推断潜在的一般特征表示

##### 4.变分自动编码器（VAE）

- 无监督，用于学习未标注数据的低维特征表示

##### 5.生成对抗网络（GAN）

- 不适用任何显式的密度函数
- 采取博弈论的方法：通过双人游戏，从训练分布中学习并生成
- 组成：
  ①生成器网络：尝试通过生成逼真的图像来欺骗鉴别器
  ②鉴别器网络：尝试区分真实图像和伪造图像

#### 图深度学习

> 这里的图不是指图像！！！

##### 1.图深度学习的应用

- Link Prediction：链接预测
- Node Classification：节点分类
- Node Importance：节点重要性（找出特殊节点）
- Graph Classification：图分类

##### 2.网络嵌入

- 目标1：重构原始的网络
- 目标2：支持网络推理（社区检测、网络距离、网络评估）

##### 3.图神经网络（GNN）

- Graph Recurrent Neural Networks（图循环神经网络）：e.g.`pagerank`
- Graph Convolutional Networks（图卷积神经网络）：

#### 前言

MiniGPT-4模型的提出，是期望模拟出类似于GPT-4的多模态能力

> 多模态大模型任务类型：图文检索、图像描述、视觉问答、视觉推理、图像生成

#### 模型架构

![image-20240508214448982](https://gitee.com/mianmann/drawing-bed-warehouse/raw/master/img/image-20240508214448982.png)

**1.Vicuna模型**

Vicuna 是一个基于解码器的语言模型，它建立在 LLaMa[37] 的基础上，可以执行广泛的复杂 语言任务。在 MiniGPT-4 中,它的主要任务是同时理解输入进来的文本与图像数据，对多个模态 的信息具有感知理解能力，生成符合指令的文本描述。在具体构建过程中，MiniGPT-4 并不从头开始训练大语言模型，而是直接利用现有的 Vicuna-13B 或 Vicuna-7B 版本，冻结所有的参数权重，降低计算开销

##### 2.视觉编码器

为了让大语言模型具备良好的视觉感知能力，MiniGPT-4 使用了与 BLIP-2相同的预训练视觉语言模型（详解多模态串讲）

##### 3.线性投影层

为了弥补视觉编码器和大语言模型之间的差距,MiniGPT-4 增加 了一个可供训练的线性投影层,期望通过训练将编码的视觉特征与 Vicuna 语言模型对齐。通过定 义一个可训练的线性投影层,将 Q-Former 输出的图像特征映射到大语言模型的表示空间,以便结 合后续的文本输入做进一步的处理和计算。
### 挑战

① 基于 LLM 的日志解析器通用性问题
② LLM 的调用成本问题
③ 日志解析的粒度评估问题

### 日志解析的粒度

提出了两个粒度的表征：特异性和适用性

![image-20240909235703692](https://gitee.com/mianmann/drawing-bed-warehouse/raw/master/img/image-20240909235703692.png)

高特异性具有更少、更详细的可变部分，适合狭窄的日志范围；低特异性具有更多可变组件，适合更广泛的日志范围

高适用性的日志模版具有广泛的通用结构，低适用性则为特定子集设计

指出 PA 和 GA 两个指标无法评估粒度差异，然后提出两个粒度指标 GGD 和 PGD

① 分组粒度距离（GGD）：这个方面强调日志消息的分组。目的是匹配预期的日志消息分组，而不要求这些组内使用相同的模板
② 解析粒度距离（PGD）：这是一个更严格的指标，要求每个日志模板精确匹配。解析模板中的差异会增加距离

### 框架

#### 前缀解析树

按顺序处理 token，遍历前缀树进行匹配，严格匹配则直接添加，没有严格匹配才使用 LLM 进行模版提取（基于 Drain 进行改编），这样大幅减少了 LLM 的调用次数

#### LLM 日志模版提取

通过 K-shot 演示进行情境学习，使用 KNN 的方法选择演示样本

#### Human-in-Loop

预处理干预（可对日志样本进行模版标注）实时校准（可用人工判断指导 LLM 决策）、后处理细化（解析后的可变部分调整）

### 总结

这篇是阿里8月最新的工作，文章做了大量实验，十分 solid，提出了很有意义的两个指标，很好的利用了无监督解析树，减小了 LLM 调用成本
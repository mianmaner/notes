#### 论文研究背景、动机和主要贡献

##### 1. 研究背景

基于日志的异常检测是智能运维领域的一个关键任务，在保证软件稳定性商起着至关重要的作用。然而，当前日志异常检测领域主要存在的问题如下：

- 当前基于日志的异常检测算法严重依赖于有大量标记数据的日志数据集，而这些数据集往往不适用于当今现实世界中的很多软件系统。

- 当前日志异常检测模型大致可分为无监督模型和有监督模型。无监督模型由于本身缺乏对异常日志事件的信息学习，所以有效性是受到很大限制的。而有监督模型的有效性很大程度上依赖于大量的标记日志。

  但在现实的软件系统中，异常隐藏在大量的系统日志中，所以识别出异常日志（从而获得准确的日志数据标签）是一项极其困难的任务。

  现有的方法主要分为两种。一种是利用聚类方法来模糊数据标签（例如 LogCluster 通过设定与异常代表类的距离阈值进行异常检测），但它们的有效性仍然需要依赖大量的标记日志；第二种是深度学习结合人工标记行为，这些模型的能力很大程度上取决于人工标签的积累，这意味着需要大量的专家知识、人力成本和时间成本。

##### 2. 动机

为了解决当前日志异常检测领域存在的这些问题，作者建议利用成熟系统（源系统）中的大量历史标记日志来协助为标记数据有限的新系统（目标系统）构建异常检测模型。通过对来自成熟系统（源系统）的标记日志进行训练，以在数据标签不足的新系统（目标系统）中实现有效的异常检测。这里将此任务称为通用跨系统日志异常检测（GCLAD）。

值得一提的是，之前一些使用迁移学习方法的相关工作（例如LogTransfer 和LogTAD）也具有这一思想，但它们的性能取决于源系统和目标系统之间的相关性，泛化能力不足（后续作者也论证了这一观点）

因此，这里作者便提出了MetaLog，一种基于meta-learning 的通用的跨系统异常检测方法。

##### 3. 主要贡献

提出了MetaLog，一种基于 Meta-learning 的新型通用跨系统日志异常检测算法。

利用全局一致的语义嵌入（GCSE）来获取全局空间中的日志事件语义嵌入向量，并为 GCLAD 任务设计元学习过程

MetaLog 在四个公共日志数据集上的评估结果表明其具有非常显著的效果

#### 论文问题描述或定义

**挑战一**：由于不同系统中的日志的在语法和语义上都有很大差异，如何弥合不同系统之间日志内容的巨大差距？

==解读：不同系统的日志的语法和语义规则有很大差异，因此对日志解析出的日志事件进行 Word Embedding 得到的特征向量差别也很大。这会导致不同系统间巨大的输入数据信息差异，因此使用一个系统中日志训练出来的模型并不会很好的适用于另一个系统。==

**挑战二**：如何使源系统日志上训练的模型具有很强的泛化能力，从而实现在仅有很少的标记日志的目标系统上具有良好的表现？

==解读：这里主要还是想让模型具有很强的 few-shot 甚至 zero-shot 的能力，从而能够很好的应用到当下实际的运维场景当中。因为真实场景下软件系统很少会有异常发生，基本不会有大量完善的标记日志数据（此类数据的收集需要专门进行混沌工程）==

#### 论文提出的新思路、新理论和新方法

##### 1. 全局一致的语义嵌入（GCSE）

GCSE阶段接收每个解析后的日志事件并生成全局一致的日志事件嵌入。

①首先通过消除非字符标记并使用 Camel Case 方法（信息检索中一种分解复合标记的方法）对日志事件进行预处理

==为了更好的理解，这里我给出BGL数据集中的一个例子：==

```Plain
ciod: LOGIN chdir(<*>) failed: Input/output error
-->
ciod login chdir failed input output error
```

②使用 Glove 的预训练词嵌入，从而保证了词嵌入分布在统一的全局空间中

==可以这么理解，因为不同系统的日志数据差异很大，如果使用源系统的日志训练 Glove 模型，那么其学习到的语义知识并不具有泛化性，所以不适用于新系统。但预训练的 Glove 模型是具有普遍共享的语义知识的，所有的单词都会在预训练数据的公共空间中进行特征映射，从而可以确保词嵌入分布在统一的全局空间中，对所有系统都“一视同仁”。==

③作者提出了一种按事件加权聚合的方法，通过其组成词生成日志事件的语义嵌入。这种聚合方法利用信息检索中的词频和逆文档频率（TF-IDF）来提取日志事件内的局部信息和整个日志数据集的全局信息。

词频定义为 $\frac{n_w}{n_e}$，其中nw是词 w 在日志事件中出现的次数，ne 是该日志事件的总字数。

逆文档频率定义为 $log(\frac{n_l}{n_l^w})$，其中$n_l$是日志事件的总数，$n_w^l$是包含词$w$的日志事件的数量

最终通过下面的加权聚合方法生成最终的日志事件嵌入

![image-20240621181452335](https://gitee.com/mianmann/drawing-bed-warehouse/raw/master/img/image-20240621181452335.png)

其中Vwi表示日志事件中第i个词的全局预训练词嵌入，Ve表示得到的全局一致的日志事件语义嵌入。

这里的 GCSE 阶段，通过普遍共享的 Glove 预训练词嵌入和每个事件的加权聚合技术这两个方法，确保了日志事件嵌入的一致性和统一性，在很大程度上有效解决了跨系统日志异常检测的挑战

==个人认为这里的加权聚合方法其实还存在另一个优点，并且是论文所没有说明的。我们知道，异常日志序列往往是隐藏在大量的正常的系统日志当中的，而这些大量正常的系统日志意义不大，而真正重要的异常日志序列出现频率却很低。这种数据的不平衡现象限制了模型的学习能力，但这里的通过 TF-IDF 来计算词嵌入的权重在一定程度上解决了这一问题。因为异常序列中的日志事件出现频率很低，其中单词的逆文档频率会很高，得到的事件嵌入权重会很高；而大量正常的系统日志事件则相反。==

##### 2. 针对跨系统日志设计的元学习

元学习的总体目标是让 MetaLog 模型具有从源日志泛化到目标日志的能力。

在元学习的训练阶段，需要使用来自至少两个系统的日志数据，分别称为源日志和目标日志。元学习的训练阶段由很多个元任务组成，同时元任务也是更新梯度的最小单位。

元任务由两个阶段组成：元训练与元测试。

在元训练阶段，MetaLog 网络使用从源日志中随机采样得到的多个源日志分片作为训练数据，记作￥￥。然后遍历每一个日志分片，计算损失函数并更新梯度。梯度更新的公式如下（其中si表示第i个日志分片）：

![image-20240622021014023](https://gitee.com/mianmann/drawing-bed-warehouse/raw/master/img/image-20240622021014023.png)

元训练阶段经过 ns 次迭代后，模型参数更新为 $\theta_S^{'}$，然后进入元测试阶段。

在元测试阶段，MetaLog 网络使用从目标日志中随机采样得到的多个目标日志分片作为测试数据，计算模型在每个数据分片下的损失函数并聚合得到元测试损失项$$。获得元测试损失项后，元学习过程使用以下方程优化 MetaLog 网络：

![image-20240622160614162](https://gitee.com/mianmann/drawing-bed-warehouse/raw/master/img/image-20240622160614162.png)

其中 θ −α∇θ LS (θ, {S }) 指的就是元训练的梯度更新，其结果就是刚才提到的$\theta_S^{'}$，α、β、γ 是元学习率超参数。这种全面的优化策略考虑了来自源日志系统和目标日志系统的信息，为 MetaLog 网络提供足够的线索来解决 GCLAD 任务

伪代码：

![image-20240622162918833](https://gitee.com/mianmann/drawing-bed-warehouse/raw/master/img/image-20240622162918833.png)

==这里综合考虑源日志系统和目标日志系统，其实就体现在最后的优化函数上，通过计算元训练的损失项和元测试的损失项加权和的梯度，来动态优化MetaLog 网络==

##### 3. MetaLog 网络架构

![image-20240622171301284](https://gitee.com/mianmann/drawing-bed-warehouse/raw/master/img/image-20240622171301284.png)

MetaLog 网络主要由三个互连模块组成：门控循环单元（GRU）、注意力掩码层和非线性层。

MetaLog 网络的输入是日志事件嵌入序列 {Ve1,Ve2, ...,Ven }，其中 et 指的是序列中的第 t 个日志事件。

 GRU模块用每个时间戳的输入维护一个隐藏状态Ht（利用基于时间戳的门控单元来实现），这允许网络保留输入日志事件序列中的长期信息。

受 Daformer 的启发，自适应注意力机制比静态线性或卷积层更有利于神经网络的泛化能力，作者在GRU模块之后设计了一个注意力掩模层。注意力模块将 GRU 模块的隐藏状态 {H1, ..., Ht } 作为输入，并利用自适应自注意力技术融合它们。

![image-20240622175402079](https://gitee.com/mianmann/drawing-bed-warehouse/raw/master/img/image-20240622175402079.png)

其中 Sum 是 t 维度的求和运算。我们还通过实验证明这种注意力机制可以帮助提高 GCLAD 任务的性能。最后，日志序列达到其最终形式 HA n ，它结合了所有先前的信息。 HA n 被馈送到非线性层，通过 tanh(WnHA n ) 生成异常概率，其中 Wn 是非线性层的网络权重。 MetaLog 网络 LS、LT 的基于元学习的训练过程所使用的损失都是通过预测异常概率和 groundtruth 计算得出的。

#### 论文方法的理论分析或实验评估方法与效果

##### 1. 论文方法的理论分析

(1) 为什么元学习相较于迁移学习更适合解决 GCLAD 任务？

作者主要从 GCLAD 任务的两个主要挑战入手，说明了元学习相较于迁移学习的优势。

第一个挑战是日志系统间的显著域差异。已经有很多论文中的理论分析表明，迁移学习难以处理动态目标源关系和分布差距较大的情况，基于迁移学习的方法的性能只能在温和的假设下得到保证，并且取决于源数据和目标数据的相关性。相比之下，元学习可以通过利用外部优化来处理更广泛的元表示，从而增强网络的泛化能力。

另一个具体挑战是数据不足。目标系统的日志数据在实际工业场景中受到严格限制，而源系统数据与机器学习社区的其他领域（例如语言或视觉任务的预训练）相比还不够充分。由于数据稀缺，基于迁移学习的方法不能很好地执行，因为它们通常基于微调并依赖于大型的预训练模型。在之前的论文中有确凿的证据表明，元学习需要更少的数据来实现与迁移学习相当的泛化结果，特别是在目标数据可访问性有限的情况下。

因此，考虑到显著的数据差异和数据稀缺性，作者所提出的 MetaLog 比以前的方法更适合和更强大地处理具有挑战性的 GCLAD 任务。

##### 2. 实验评估方法

(1) 数据集

我们使用四个公开可用的日志数据集进行了全面的实验：HDFS 、BGL 、Thunderbird 和 OpenStack。 为了确保兼容性，作者选择HDFS和BGL数据集进行双边泛化，而OpenStack和Thunderbird数据集用于零样本泛化。

(2) 评估场景

作者设定了两种评估场景，分别是双边泛化和零样本泛化。在双边泛化场景中，使用带标签的源系统日志和有限数量的带标签的目标系统日志来训练模型，然后对目标系统日志进行异常检测。在零样本泛化场景中，模型仅在多个标记的源系统日志上进行训练，并直接部署在第三个目标系统日志上进行异常检测。

##### 3. 实验效果

(1)双边泛化场景

MetaLog方法显著优于其他跨系统检测方法，包括直接零样本、基于TCA的迁移和最新的迁移学习方法。MetaLog不仅在少量目标日志数据和稀缺异常标签的情况下表现优异，还能在许多情况下超越直接在目标数据上训练的（半）监督方法。这表明，元学习技术在处理跨系统日志异常检测任务时，比传统的迁移学习方法更有效，尤其在处理数据分布不平衡问题时，表现尤为出色。

(2)零样本泛化场景

在零样本泛化场景下，实验结果表明，MetaLog在处理新系统的日志时表现最好，显著优于其他两种方法。然而，由于源系统和目标系统的日志分布存在巨大差异，MetaLog 的F1分数不太理想，整体效果仍有提升空间。

#### 总结

##### 1. 论文的优点

论文指出了基于迁移学习方式解决 GCLAD 任务的缺点，并创新性的将元学习范式引入到了 GCLAD 任务中并通过实验证明了其性能优势，为后续相关研究提供了新思路。

论文设计了全局一致的语义嵌入（GCSE）阶段，通过普遍共享的 Glove 预训练词嵌入和每个事件的加权聚合技术这两个方法，确保了日志事件嵌入的一致性和统一性，在很大程度上有效解决了跨系统日志异常检测的挑战。同时在加权聚合时引入了信息检索领域的 TF-IDF 方法，在一定程度上解决了无意义的大量正常系统日志远大于有意义的异常日志序列的数据不平衡问题。

##### 2. 本文带来的启示

基于元学习的方式相较于基于迁移学习的方式更加适合处理 GCLAD 任务

显著的数据分布差异是零样本泛化场景下的的主要障碍

##### 3. 后续的研究思路

作者提出未来的主要重点将是解决最具挑战性的零样本泛化场景。为了实现这一目标，作者计划探索使用 LLM 来捕获来自多个成熟系统的异常日志的特征。通过采用即时学习技术，目标将 MetaLog 的异常检测能力推广到新系统并实现可用的性能。

##### 4. 对后续研究的一些思考

- 尝试使用预训练的 LLM 去做日志的嵌入的确更好，既适应 few-shot 和 zero-shot 的方式，又能更好提取语义信息（这种方式的有效性也已经在 neurallog、biglog 等论文中得到了验证）

  日志解析方法表格

- 未来可以尝试多模态？指标数据和调用链数据也变得越来越重要，并且多项工作表明各个数据之间是具有互补效应的，日志数据信息的缺点在于日志是开发人员人为设定的，尝试与指标数据、调用链数据结合

- 不同系统间除了日志语法和语义的巨大差异之外，其实也存在异常种类的巨大差异。而这些训练数据中没有出现的新异常所对应的日志异常序列的特征，这一点论文中并没有提及。


